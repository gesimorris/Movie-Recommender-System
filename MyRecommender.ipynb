{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be building a movie recommender system using Python and Pandas. \n",
    "I will be using the Collabrotive-Filtering approach to build the system. More specifically, I will be using the Memory Based Filtering approach as well as the Model Based filtering approach to get my results.\n",
    "\n",
    "The Memory-Based CF approach will use cosine similairty while the Model Based CF approach will use singular value decomposition. Collaborative Filtering recommends items based on similarity measures between users and/or items. \n",
    "\n",
    "The data used for this recommender system is the popular MovieLens dataset, which is one of the most common datasets used when implementing and testing recommender engines. It contains 100k movie ratings from 943 users and a selection of 1682 movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import the libraries we will be using and load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Reading the dataset\n",
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('u.data', sep='\\t', names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at the head of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        0       50       5  881250949\n",
       "1        0      172       5  881250949\n",
       "2        0      133       1  881250949\n",
       "3      196      242       3  881250949\n",
       "4      186      302       3  891717742"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets grab the movie titles since we don't have that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Shanghai Triad (Yao a yao yao dao waipo qiao) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Twelve Monkeys (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Babe (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Dead Man Walking (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Richard III (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                                              title\n",
       "0        1                                   Toy Story (1995)\n",
       "1        2                                   GoldenEye (1995)\n",
       "2        3                                  Four Rooms (1995)\n",
       "3        4                                  Get Shorty (1995)\n",
       "4        5                                     Copycat (1995)\n",
       "5        6  Shanghai Triad (Yao a yao yao dao waipo qiao) ...\n",
       "6        7                              Twelve Monkeys (1995)\n",
       "7        8                                        Babe (1995)\n",
       "8        9                            Dead Man Walking (1995)\n",
       "9       10                                 Richard III (1995)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = pd.read_csv(\"Movie_Id_Titles\")\n",
    "movie_titles.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's merge the movie titles with our dataframe using the item_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>880473582</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>891271545</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>888552084</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>879362124</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>274</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>878944679</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>227</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>879035347</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>885679998</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>305</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>886321799</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>108</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>879879739</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>875747292</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>234</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>892079237</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>884239471</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>117</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>880126022</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>884064188</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>318</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>884495696</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>885557660</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>124</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>890287508</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>253</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>891628518</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>271</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>885848640</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  item_id  rating  timestamp             title\n",
       "0         0       50       5  881250949  Star Wars (1977)\n",
       "1       290       50       5  880473582  Star Wars (1977)\n",
       "2        79       50       4  891271545  Star Wars (1977)\n",
       "3         2       50       5  888552084  Star Wars (1977)\n",
       "4         8       50       5  879362124  Star Wars (1977)\n",
       "5       274       50       5  878944679  Star Wars (1977)\n",
       "6       227       50       4  879035347  Star Wars (1977)\n",
       "7        99       50       5  885679998  Star Wars (1977)\n",
       "8       305       50       5  886321799  Star Wars (1977)\n",
       "9       108       50       4  879879739  Star Wars (1977)\n",
       "10       63       50       4  875747292  Star Wars (1977)\n",
       "11      234       50       4  892079237  Star Wars (1977)\n",
       "12       97       50       5  884239471  Star Wars (1977)\n",
       "13      117       50       5  880126022  Star Wars (1977)\n",
       "14       70       50       4  884064188  Star Wars (1977)\n",
       "15      318       50       2  884495696  Star Wars (1977)\n",
       "16      145       50       5  885557660  Star Wars (1977)\n",
       "17      124       50       3  890287508  Star Wars (1977)\n",
       "18      253       50       4  891628518  Star Wars (1977)\n",
       "19      271       50       5  885848640  Star Wars (1977)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df,movie_titles,on='item_id')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the number of unique movie titles and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of Users: 944\n",
      "Num of Movies: 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.nunique()\n",
    "n_items = df.item_id.nunique()\n",
    "\n",
    "print('Num. of Users: '+ str(n_users))\n",
    "print('Num of Movies: '+str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the recommender system, lets split the data into two sets using the Train test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Based Filtering\n",
    "\n",
    "This approach can be divided into two sections: user-item filtering and item-item filtering.\n",
    "\n",
    "*User-item filtering* takes a particular user, finds users that are similar based on similarity of ratings, recommend items that those similar users liked. \n",
    "\n",
    "In contrast, *item-item filtering* will take an item, find users who liked that item, and find other items that those users or similar users also liked. It takes items and outputs other items as recommendations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases, I will create a user-item matrix with the entire dataset. \n",
    "\n",
    "The dataset has been split into two: train_data and test_data so I will need to create two matrices. The size of the matrices will be [944,1682]. The training matrix will contain 75% of ratings and the testing matrix will contain 25%.\n",
    "\n",
    "Lets create the two matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrix 1 for training data\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[3]-1] = line[3]\n",
    "\n",
    "#Matrix 2 for testing data\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A distance metric commonly used in recommender systems is cosine similarity, where the ratings are seen as vectors in n-dimensional space and the similarity is calculated based on the angle between these vectors. Cosine similiarity for users a and m can be calculated using the formula below, where you take dot product of the user vector  ùë¢ùëò and the user vector  ùë¢ùëé and divide it by multiplication of the Euclidean lengths of the vectors.\n",
    "\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?s_u^{cos}(u_k,u_a)=\\frac{u_k&space;\\cdot&space;u_a&space;}{&space;\\left&space;\\|&space;u_k&space;\\right&space;\\|&space;\\left&space;\\|&space;u_a&space;\\right&space;\\|&space;}&space;=\\frac{\\sum&space;x_{k,m}x_{a,m}}{\\sqrt{\\sum&space;x_{k,m}^2\\sum&space;x_{a,m}^2}}\"/>\n",
    "\n",
    "In the memory-based approach, the cosine similarity between the users to find out the users with similar interests, larger cosine implies that there is a smaller angle between two users, hence they have similar interests.\n",
    "\n",
    "Lets use the pairwise funciton in sklearn to calculate the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to make predictions. The similary matrices have been created as user_similarity and item_similarity so I can now predict based on the user-based CF formula.\n",
    "\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?\\hat{x}_{k,m}&space;=&space;\\bar{x}_{k}&space;&plus;&space;\\frac{\\sum\\limits_{u_a}&space;sim_u(u_k,&space;u_a)&space;(x_{a,m}&space;-&space;\\bar{x_{u_a}})}{\\sum\\limits_{u_a}|sim_u(u_k,&space;u_a)|}\"/>\n",
    "\n",
    "For user based CF, the similarity between the two users in the formula needs to be normalized so that the ratings stay between 1 and 5 and, as a final step, I will need to sum the average ratings for the user that you are trying to predict. \n",
    "\n",
    "The idea here is that some users may tend always to give high or low ratings to all movies. The relative difference in the ratings that these users give is more important than the absolute values. To give an example: suppose, user k gives 4 stars to his favourite movies and 3 stars to all other good movies. Suppose now that another user t rates movies that he/she likes with 5 stars, and the movies he/she fell asleep over with 3 stars. These two users could have a very similar taste but treat the rating system differently.\n",
    "\n",
    "When making a prediction for item-based CF you don't need to correct for users average rating since query user itself is used to do predictions\n",
    "\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?\\hat{x}_{k,m}&space;=&space;\\frac{\\sum\\limits_{i_b}&space;sim_i(i_m,&space;i_b)&space;(x_{k,b})&space;}{\\sum\\limits_{i_b}|sim_i(i_m,&space;i_b)|}\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        #Get the mean of ratings\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        #Use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        #Add the mean \n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.29118372e-03 4.33209054e-04 2.30294348e-04 ... 8.92325996e-03\n",
      "  8.92325996e-03 8.92325996e-03]\n",
      " [1.29118372e-03 4.33209054e-04 2.30294348e-04 ... 8.92325996e-03\n",
      "  8.92325996e-03 8.92325996e-03]\n",
      " [1.29118372e-03 4.33209054e-04 2.30294348e-04 ... 8.92325996e-03\n",
      "  8.92325996e-03 8.92325996e-03]\n",
      " ...\n",
      " [1.10677853e-03 3.40988661e-04 9.27064997e-05 ... 7.13860797e-03\n",
      "  7.13860797e-03 7.13860797e-03]\n",
      " [1.29118372e-03 4.33209054e-04 2.30294348e-04 ... 8.92325996e-03\n",
      "  8.92325996e-03 8.92325996e-03]\n",
      " [4.68726700e-04 2.63173920e-04 1.60801403e-04 ... 3.56930399e-03\n",
      "  3.56930399e-03 3.56930399e-03]]\n",
      "[[ 3.69384319e-01  1.39466372e+00  2.54534559e+00 ...  2.69678633e-03\n",
      "   2.69678633e-03  2.69678633e-03]\n",
      " [ 3.69384319e-01  1.39466372e+00  2.54534559e+00 ...  2.69678633e-03\n",
      "   2.69678633e-03  2.69678633e-03]\n",
      " [ 3.69384319e-01  1.39466372e+00  2.54534559e+00 ...  2.69678633e-03\n",
      "   2.69678633e-03  2.69678633e-03]\n",
      " ...\n",
      " [ 7.17860463e-01  1.94081707e+00  2.86880616e+00 ... -8.69693485e-04\n",
      "  -8.69693485e-04 -8.69693485e-04]\n",
      " [ 3.69384319e-01  1.39466372e+00  2.54534559e+00 ...  2.69678633e-03\n",
      "   2.69678633e-03  2.69678633e-03]\n",
      " [ 6.90011827e-01  1.85689684e+00  2.95774479e+00 ... -4.80728198e-03\n",
      "  -4.80728198e-03 -4.80728198e-03]]\n"
     ]
    }
   ],
   "source": [
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')\n",
    "item_prediction = predict(train_data_matrix, item_similarity, type='item')\n",
    "\n",
    "print(item_prediction)\n",
    "print(user_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the accuracy of the predicted ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 3.6865442211762627\n",
      "Item-based CF RMSE:3.6891931532904922\n"
     ]
    }
   ],
   "source": [
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print('Item-based CF RMSE:' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "To conclude, the low user based RMSE indicates that the recommender system accurately predicts ratings by leveraging user-user similarities effectively and the low item based RMSE indicates that the recommender system accurately predicts ratings by leveraging item-item similarities effectively.\n",
    "\n",
    "However, considerations such as sparsity, scale and distribution of ratings can make RMSE to be less informative on its own and should be interpreted alongside other metrics. Model-based CF methods are scalable and can deal with higher sparsity level than memory-based models, but also suffer when new users or items that don't have any ratings enter the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based Collaborative Filtering\n",
    "\n",
    "The model based CF approach uses statistical methods to learn patterns and make predictions based on those patterns. One of these methods are **matrix factorization(MF)**. MF can deal better with scalabilty and sparsity for recommender systems better than Memory Based. MF decomposes the user-item interaction matrix into lower-dimensional matrices, revealing latent factors for users and items.\n",
    "\n",
    "Let's calculate the sparsity level of MovieLens dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of MovieLens is 93.7%\n"
     ]
    }
   ],
   "source": [
    "sparsity = sparsity=round(1.0-len(df)/float(n_users*n_items),3)\n",
    "print('The sparsity level of MovieLens is ' +  str(sparsity*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learned latent preferences of the user can allow the model to learn which data is most important on its own even if that data is not a variable. The important aspect is that the CF model only uses data (user_id, movie_id, rating) to learn the latent features. If there is little data available model-based CF model will predict poorly, since it will be more difficult to learn the latent features.\n",
    "\n",
    "# SVD\n",
    "\n",
    "The general equation can be expressed as follows:\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?X=USV^T\" title=\"X=USV^T\" />\n",
    "\n",
    "\n",
    "Given `m x n` matrix `X`:\n",
    "* *`U`* is an *`(m x r)`* orthogonal matrix\n",
    "* *`S`* is an *`(r x r)`* diagonal matrix with non-negative real numbers on the diagonal\n",
    "* *V^T* is an *`(r x n)`* orthogonal matrix\n",
    "\n",
    "Elements on the diagnoal in `S` are known as *singular values of `X`*. \n",
    "\n",
    "Matrix *`X`* can be factorized to *`U`*, *`S`* and *`V`*. The *`U`* matrix represents the feature vectors corresponding to the users in the hidden feature space and the *`V`* matrix represents the feature vectors corresponding to the items in the hidden feature space.\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" style=\"max-width:100%; width: 50%; max-width: none\" src=\"http://s33.postimg.org/kwgsb5g1b/BLOG_CCA_5.png\"/>\n",
    "\n",
    "Now I can make a prediction by taking dot product of *`U`*, *`S`* and *`V^T`*.\n",
    "\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" style=\"max-width:100%; width: 50%; max-width: none\" src=\"http://s33.postimg.org/ch9lcm6pb/BLOG_CCA_4.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 3.6870552240169934\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#get SVD components from train matrix. Choose k.\n",
    "u, s, vt = svds(train_data_matrix, k = 20)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "print('User-based CF MSE: ' + str(rmse(X_pred, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we have seen two collaborative filtering methods, memory based and model based. **Memory-based models** are based on similarity between items or users, where we use cosine-similarity. **Model-based CF** is based on matrix factorization where we use SVD to factorize the matrix. SVD in recommender systems leverages matrix factorization to break down the user-item interaction matrix into latent factors. These factors are then used to predict missing ratings and make personalized recommendations by capturing the underlying relationships in user preferences and item characteristics. This approach is particularly effective in handling large and sparse datasets, making it a cornerstone of modern recommender systems.However, if little data is provided, this method becomes less effective.\n",
    "\n",
    "To improve on this system, implementing a user interface which displays the recommended movies would be the next step. There are also many other methods to get the recommendations. By impementing them as well, I can see which method gives the most accurate recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
